{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe8ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34261d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing...\n"
     ]
    }
   ],
   "source": [
    "with open('config.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "data_path = parameters['data_path']\n",
    "batch_size = parameters['batch_size']\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "## inference\n",
    "print('Inferencing...')\n",
    "names = ['puma', 'tract']\n",
    "training_portions = parameters['training_portions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f038a",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92512a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_name = 'puma'\n",
    "super_res_name = 'tract'\n",
    "original_losses = []\n",
    "for training_portion in training_portions:\n",
    "\n",
    "    parameters['training_portion'] = training_portion\n",
    "    \n",
    "    ## load data\n",
    "    dataset_train, _, dataset_test, X_max = load_data(low_res_name, super_res_name, parameters)\n",
    "    linkage = dataset_train.linkage\n",
    "    super_adj = dataset_train.adj_super.to(device)\n",
    "    \n",
    "    ## load model\n",
    "    model = GraphSR(linkage, super_adj).to(device)\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    model.load_state_dict(torch.load(f'model_state/graphSR_{low_res_name}_{super_res_name}_{training_portion}_0'))\n",
    "    \n",
    "    ## pred\n",
    "    loss, _, _, _ = evaluation(model, criterion, device, batch_size, dataset_test)\n",
    "    original_losses.append(loss*X_max.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a1123",
   "metadata": {},
   "source": [
    "### Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22a5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_losses = []\n",
    "for training_portion in training_portions:\n",
    "\n",
    "    parameters['training_portion'] = training_portion\n",
    "    \n",
    "    ## load data\n",
    "    dataset_train, _, dataset_test, X_max = load_data(low_res_name, super_res_name, parameters)\n",
    "    linkage = dataset_train.linkage\n",
    "    super_adj = dataset_train.adj_super.to(device)\n",
    "    \n",
    "    ## load model\n",
    "    model = GraphSR(linkage, super_adj).to(device)\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    model.load_state_dict(torch.load(f'model_state/graphSR_{low_res_name}_{super_res_name}_{training_portion}_1'))\n",
    "    \n",
    "    ## pred\n",
    "    loss, _, _, _ = evaluation(model, criterion, device, batch_size, dataset_test)\n",
    "    fine_tune_losses.append(loss*X_max.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47930d0",
   "metadata": {},
   "source": [
    "### Simple Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b20bdfb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Portion: 0.01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 5165.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Portion: 0.05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 7089.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Portion: 0.1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 312/312 [00:00<00:00, 7254.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Portion: 0.5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:00<00:00, 7201.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Portion: 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3127/3127 [00:00<00:00, 7253.58it/s]\n"
     ]
    }
   ],
   "source": [
    "ratio_losses = []\n",
    "for training_portion in training_portions:\n",
    "    parameters['training_portion'] = training_portion\n",
    "    print(f'Training Portion: {training_portion}...')\n",
    "    ## load data\n",
    "    dataset_train, _, dataset_test,_ = load_data(low_res_name, super_res_name, parameters)\n",
    "    low_res_data = dataset_train.att_low.squeeze_(-1)\n",
    "    super_res_data = dataset_train.att_super.squeeze_(-1)\n",
    "    linkage = dataset_train.linkage\n",
    "\n",
    "    ## ratio\n",
    "    ratio_matrix = torch.zeros_like(linkage)\n",
    "    for i in tqdm(range(low_res_data.size(0))):\n",
    "        proj = (low_res_data[i].unsqueeze(-1)*linkage)\n",
    "        rep_super = super_res_data[i].unsqueeze(0).repeat(low_res_data.size(1),1)\n",
    "        ratio = rep_super/proj\n",
    "        ratio[torch.isinf(ratio)] = 0\n",
    "        ratio[torch.isnan(ratio)] = 0    \n",
    "        ratio_matrix += ratio\n",
    "    ratio_matrix /= low_res_data.size(0)\n",
    "    \n",
    "    ## prediction\n",
    "    pred = []\n",
    "    test_new = dataset_test.att_low.clone()\n",
    "    pred = torch.stack([torch.sum(test_new[i]*ratio_matrix, axis=0) for i in range(len(dataset_test))])\n",
    "    true = dataset_test.att_super.squeeze_(-1)\n",
    "    ratio_losses.append(criterion(pred, true).item()*X_max.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16af7064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.656804041005671,\n",
       " 0.6363179641775787,\n",
       " 0.6354206940159202,\n",
       " 0.6260007689706981,\n",
       " 0.6222707633860409]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84283e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6741015259176493,\n",
       " 0.6545765739865601,\n",
       " 0.6482034148648381,\n",
       " 0.6368742152117193,\n",
       " 0.633577136322856]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37697e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6972910067997873,\n",
       " 0.6911702030338347,\n",
       " 0.6901924386620522,\n",
       " 0.690417401958257,\n",
       " 0.6900453264825046]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
