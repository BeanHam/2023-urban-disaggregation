{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af46d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c01801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration...\n"
     ]
    }
   ],
   "source": [
    "#--------------------\n",
    "# Parameters\n",
    "#--------------------\n",
    "data_name='taxi'\n",
    "print(f\"Load configuration...\")      \n",
    "with open('parameters.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "if data_name == 'taxi':\n",
    "    parameters['root']=\"D:/all-data/nyc-taxi/raw_chunk_data/\"\n",
    "    parameters['year']=\"2016\"\n",
    "elif data_name == 'bikeshare': \n",
    "    parameters['root']=\"D:/all-data/nyc-bikeshare/raw_data/\"\n",
    "    parameters['year']=\"2021\"\n",
    "else: \n",
    "    parameters['root']=\"D:/all-data/nyc-911/911.csv\"\n",
    "    parameters['year']=\"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4809ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = parameters['year']\n",
    "root = parameters['root']\n",
    "column_names = parameters['column_names']\n",
    "uni_columns = parameters['uni_columns']\n",
    "lat_upper = parameters['lat_upper']\n",
    "lat_bottom = parameters['lat_bottom']\n",
    "long_right = parameters['long_right']\n",
    "long_left = parameters['long_left']\n",
    "\n",
    "tract_root = parameters['tract']\n",
    "boundary_root = parameters['boundary']\n",
    "boundary = get_boundary(boundary_root, parameters)\n",
    "geodata_tract = get_geodata(tract_root, boundary, data_name, 'tract')\n",
    "geodata_tract = geopandas.GeoDataFrame(geodata_tract, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0f6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -- Load 2016 data...\n"
     ]
    }
   ],
   "source": [
    "print(f\"   -- Load {year} data...\")\n",
    "dirt = root + year + '/'\n",
    "files = os.listdir(dirt)\n",
    "variables = column_names[year]\n",
    "whole_data = []\n",
    "for file in files:\n",
    "    \n",
    "    data = pd.read_csv(dirt + file)\n",
    "    data = data[variables]\n",
    "    data.columns = uni_columns\n",
    "    \n",
    "    ## subset data to regions of our interest\n",
    "    ## (for faster processing purpose as well)        \n",
    "    data = data.loc[(data.lat<= lat_upper) &\\\n",
    "                    (data.lat>= lat_bottom) &\\\n",
    "                    (data.long<= long_right) &\\\n",
    "                    (data.long>= long_left)]\n",
    "    data = geopandas.GeoDataFrame(data, geometry=geopandas.points_from_xy(data.long, data.lat))\n",
    "    whole_data.append(data.values)\n",
    "whole_data = pd.DataFrame(np.concatenate(whole_data), columns=uni_columns+['geometry'])\n",
    "whole_data = geopandas.GeoDataFrame(whole_data, geometry='geometry')\n",
    "\n",
    "## extract date & time\n",
    "if year != '2016':\n",
    "    dates = [record[5:10] for record in whole_data.pickup_datetime]\n",
    "    times = [record[11:13] for record in whole_data.pickup_datetime]\n",
    "    whole_data['date'] = dates\n",
    "    whole_data['time'] = times\n",
    "else:\n",
    "    dates = [record[:5] for record in whole_data.pickup_datetime]\n",
    "    times = [record[11:13]+record[-2:] for record in whole_data.pickup_datetime]\n",
    "    times = np.array(list(map(change_time_format, times)))\n",
    "    \n",
    "    ## 12 -> 12AM; should be changed to 00\n",
    "    ## 24 -> 12PM; should stay as 12\n",
    "    times[times == '12'] = '00'\n",
    "    times[times == '24'] = '12'\n",
    "    whole_data['date'] = dates\n",
    "    whole_data['time'] = times\n",
    "    \n",
    "## unique dates & unique times & segmentations\n",
    "UNIQUE_DATES = np.unique(dates)\n",
    "UNIQUE_TIME = np.unique(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Count Function\n",
    "#----------------------\n",
    "def count(geodata, \n",
    "          hourly_data):\n",
    "    data = geopandas.sjoin(geodata, hourly_data)\n",
    "    data['index'] = data.index\n",
    "    data_count = np.zeros(len(geodata))\n",
    "    data_count[np.unique(data.index)] = data.groupby('index').count()['geometry'].values\n",
    "    return data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9108fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06/01, 12AM-1AM\n",
    "uni_date = '06/01'\n",
    "uni_time = '00'\n",
    "query = f\"date == '{uni_date}' & time == '{uni_time}'\"\n",
    "hourly_data = whole_data.query(query)\n",
    "hourly_data = hourly_data.reset_index()\n",
    "count_data = geopandas.sjoin(geodata_tract, hourly_data)\n",
    "count_data['index'] = count_data.index\n",
    "#sub_count_data = count_data[count_data.index == 2]\n",
    "#points = hourly_data.iloc[sub_count_data.index_right.values]\n",
    "#points.to_csv('tract-12am-1am-points.csv', index=False)\n",
    "hourly_data.to_csv('12am-1am-points-hourly-data.csv', index=False)\n",
    "count_data.to_csv('12am-1am-points-count-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbd7ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 280, 281, 281], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8df1261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06/01, 12AM-1AM\n",
    "uni_date = '06/01'\n",
    "uni_time = '12'\n",
    "query = f\"date == '{uni_date}' & time == '{uni_time}'\"\n",
    "hourly_data = whole_data.query(query)\n",
    "hourly_data = hourly_data.reset_index()\n",
    "count_data = geopandas.sjoin(geodata_tract, hourly_data)\n",
    "count_data['index'] = count_data.index\n",
    "#count_data = count_data[count_data.index == 2]\n",
    "#points = hourly_data.iloc[count_data.index_right.values]\n",
    "#points.to_csv('tract-12pm-1pm-points.csv', index=False)\n",
    "hourly_data.to_csv('12pm-1pm-points-hourly-data.csv', index=False)\n",
    "count_data.to_csv('12pm-1pm-points-count-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2ed5cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 281, 281, 281], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data.index.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
